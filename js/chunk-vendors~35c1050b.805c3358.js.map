{"version":3,"sources":["webpack:///./node_modules/markdown-it-emoji/lib/render.js","webpack:///./node_modules/markdown-it-toc-and-anchor/dist/index.js","webpack:///./node_modules/markdown-it-emoji/index.js","webpack:///./node_modules/markdown-it-emoji/lib/normalize_opts.js","webpack:///./node_modules/markdown-it-emoji/lib/replace.js","webpack:///./node_modules/markdown-it-mark/index.js","webpack:///./node_modules/markdown-it-abbr/index.js","webpack:///./node_modules/markdown-it-sub/index.js","webpack:///./node_modules/markdown-it-sup/index.js","webpack:///./node_modules/markdown-it-katex/index.js","webpack:///./node_modules/markdown-it-emoji/lib/data/shortcuts.js","webpack:///./node_modules/markdown-it-task-lists/index.js","webpack:///./node_modules/markdown-it-ins/index.js","webpack:///./node_modules/markdown-it-footnote/index.js","webpack:///./node_modules/markdown-it-deflist/index.js"],"names":[],"mappings":";;;;;;AAAa;;AAEb;AACA;AACA;;;;;;;;;ACJa;;AAEb;AACA;AACA,CAAC;AACD;;AAEA,oCAAoC,mBAAO,CAAC,MAAO;;AAEnD,oCAAoC,mBAAO,CAAC,MAAO;;AAEnD,oCAAoC,mBAAO,CAAC,MAAuB;;AAEnE,sCAAsC,uCAAuC,gBAAgB;;AAE7F,uBAAuB,2EAA2E,kCAAkC,mBAAmB,GAAG,EAAE,OAAO,kCAAkC,8HAA8H,GAAG,EAAE,qBAAqB;;AAE7V,kCAAkC,iFAAiF;;AAEnH,+BAA+B,wEAAwE;;AAEvG,iCAAiC,+HAA+H;;AAEhK,kCAAkC,0BAA0B,8CAA8C,gBAAgB,OAAO,kBAAkB,EAAE,aAAa,EAAE;;AAEpK,gCAAgC,gBAAgB,sBAAsB,OAAO,uDAAuD,mCAAmC,0DAA0D,sFAAsF,gEAAgE,EAAE,GAAG,EAAE,iCAAiC,2CAA2C,EAAE,EAAE,EAAE,eAAe;;AAE/d,2CAA2C,kBAAkB,kCAAkC,qEAAqE,EAAE,EAAE,OAAO,kBAAkB,EAAE,YAAY;;AAE/M;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,8BAA8B;;AAE9B;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,yBAAyB;AACzB;AACA,GAAG;AACH;;AAEA;AACA;AACA,4BAA4B;AAC5B;AACA,KAAK,mBAAmB;AACxB;AACA,KAAK;AACL,GAAG;AACH,4BAA4B;AAC5B;AACA,KAAK;AACL;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA,sCAAsC;AACtC;AACA,GAAG;;AAEH;;AAEA;AACA;AACA;AACA,GAAG;AACH;;AAEA,mHAAmH;AACnH;;AAEA;AACA;AACA;AACA,MAAM;;AAEN;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA,IAAI;;AAEJ;AACA;AACA;AACA;;AAEA;AACA;;AAEA,UAAU,+CAA+C;AACzD;AACA;AACA,qBAAqB;AACrB;AACA,SAAS;AACT;;AAEA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH,qDAAqD;;AAErD;AACA;AACA,8BAA8B;;AAE9B;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,mBAAmB,mBAAmB;AACtC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA,8DAA8D,EAAE;;AAEhE;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;;;AAGL;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA,KAAK;;;AAGL;AACA;AACA;AACA,+CAA+C;;AAE/C;AACA;AACA,GAAG;;AAEH;AACA,uEAAuE,aAAa;AACpF;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0EAA0E,eAAe;AACzF;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,C;;;;;;;;ACtUa;;;AAGb,wBAAwB,mBAAO,CAAC,MAAsB;AACtD,wBAAwB,mBAAO,CAAC,MAAsB;AACtD,wBAAwB,mBAAO,CAAC,MAAc;AAC9C,wBAAwB,mBAAO,CAAC,MAAe;AAC/C,wBAAwB,mBAAO,CAAC,MAAsB;;;AAGtD;AACA;AACA;AACA;AACA;AACA;;AAEA,8CAA8C,yBAAyB;;AAEvE;;AAEA;AACA;;;;;;;;;ACtBA;AACA;;AAEa;;;AAGb;AACA,sCAAsC;AACtC;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;;AAEA,0CAA0C;AAC1C;AACA;AACA,wBAAwB,YAAY;;AAEpC;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA,GAAG,IAAI;;AAEP;AACA;AACA,sCAAsC,yBAAyB,EAAE;AACjE;AACA;AACA;AACA,sCAAsC,sBAAsB,EAAE;AAC9D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;;AAEa;;;AAGb;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,uCAAuC,OAAO;AAC9C,6CAA6C,UAAU;AACvD;;AAEA;AACA;AACA,iCAAiC,QAAQ;AACzC;;AAEA;AACA,sCAAsC,gCAAgC;AACtE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxFa;;;AAGb;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,cAAc;;AAE/B,iCAAiC,cAAc;;AAE/C;AACA;AACA;;AAEA,kBAAkB,cAAc;;AAEhC;AACA;AACA;AACA;AACA;;AAEA,eAAe,SAAS;AACxB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe,SAAS;AACxB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;ACvHA;AACA;AACa;;;AAGb;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA,yBAAyB,cAAc;;AAEvC,sDAAsD,cAAc;AACpE,sDAAsD,cAAc;;AAEpE;;AAEA,UAAU,WAAW;AACrB;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;;AAEA,iBAAiB,aAAa;;AAE9B;AACA;AACA,6BAA6B,cAAc;AAC3C,6BAA6B,cAAc;AAC3C,mCAAmC,8BAA8B;AACjE;AACA;AACA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;AACA;AACA;;AAEA,mCAAmC,QAAQ;;AAE3C;AACA;AACA;AACA,OAAO;AACP;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,qBAAqB;AACrB;AACA;;AAEA;;AAEA,uCAAuC,OAAO;AAC9C,6CAA6C,UAAU;AACvD;;AAEA;AACA,iCAAiC,QAAQ;AACzC;AACA,2CAA2C,UAAU;;AAErD;AACA;AACA;AACA;;AAEA;AACA;AACA,oCAAoC,UAAU;;AAE9C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,4BAA4B,UAAU;;AAEtC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,4DAA4D,oCAAoC;;AAEhG;AACA;;;;;;;;;ACnJA;;AAEa;;AAEb;AACA,2CAA2C,YAAY,EAAE;;;AAGzD;AACA;AACA;AACA;AACA;AACA;;AAEA,oDAAoD,cAAc;AAClE,eAAe,cAAc,EAAE;AAC/B,yBAAyB,cAAc;;AAEvC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;;;;;;;;ACjEA;;AAEa;;AAEb;AACA,2CAA2C,YAAY,EAAE;;AAEzD;AACA;AACA;AACA;AACA;AACA;;AAEA,oDAAoD,cAAc;AAClE,eAAe,cAAc,EAAE;AAC/B,yBAAyB,cAAc;;AAEvC;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;;;;;;;;;AChEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACa;;AAEb,YAAY,mBAAO,CAAC,MAAO;;AAE3B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,uCAAuC,cAAc;;AAErD;AACA;AACA,sBAAsB,sBAAsB;AAC5C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,UAAU;;AAEnD;AACA,yCAAyC,OAAO;AAChD;AACA;;AAEA;AACA;AACA,sBAAsB,sBAAsB;AAC5C;AACA;AACA;;AAEA;AACA;AACA,sBAAsB,uBAAuB;AAC7C;AACA;AACA;;AAEA;AACA;AACA;AACA,sBAAsB,sBAAsB;AAC5C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,sBAAsB,cAAc;AACpC,0CAA0C,cAAc;;AAExD;AACA;;AAEA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA;;AAEA,qBAAqB,QAAQ;;AAE7B;;AAEA,wBAAwB,OAAO;;AAE/B;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,oBAAoB;AACzD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,oBAAoB;AACzD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;;;;;;;;ACpMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACa;;AAEb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,MAAM;AAC/C;AACA;AACA;AACA;AACA;AACA,wBAAwB,MAAM;AAC9B;;;;;;;;ACxCA,wDAAwD;AACxD;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iBAAiB,mBAAmB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;;AAEA;AACA;AACA;;AAEA;AACA;AACA,EAAE;AACF;AACA;AACA;;AAEA;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAAE;AACF;AACA;AACA;AACA;;AAEA,8CAA8C;AAC9C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA;;AAEA,0BAA0B,gCAAgC;AAC1D,6BAA6B,wCAAwC;AACrE,4BAA4B,wCAAwC;;AAEpE;AACA;AACA;AACA;;;;;;;;;ACnHa;;;AAGb;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,cAAc;;AAE/B,iCAAiC,cAAc;;AAE/C;AACA;AACA;;AAEA,kBAAkB,cAAc;;AAEhC;AACA;AACA;AACA;AACA;;AAEA,eAAe,SAAS;AACxB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;;AAEA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe,SAAS;AACxB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;ACvHA;AACA;AACa;;AAEb;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE;AACtE;;AAEA;;;AAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B,cAAc;;AAExC,sDAAsD,cAAc;AACpE,0DAA0D,cAAc;;AAExE,yBAAyB,WAAW;AACpC,+CAA+C,cAAc;AAC7D;AACA;AACA;AACA;;AAEA,4BAA4B,cAAc,EAAE;AAC5C,yEAAyE,cAAc;AACvF,iBAAiB,aAAa;AAC9B;;AAEA,+BAA+B,0BAA0B;AACzD,oCAAoC,+BAA+B;AACnE;AACA;;AAEA;AACA,mBAAmB;AACnB;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,2BAA2B,cAAc;AACzC,sDAAsD,cAAc;AACpE,0DAA0D,cAAc;;AAExE;AACA;;AAEA;AACA,uBAAuB,cAAc;;AAErC;AACA;AACA;AACA;AACA,iCAAiC,0BAA0B;AAC3D,sCAAsC,+BAA+B;AACrE;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oBAAoB;;AAEpB,8CAA8C;AAC9C;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,0BAA0B,cAAc;;AAExC,4DAA4D,cAAc;AAC1E,sDAAsD,cAAc;AACpE,0DAA0D,cAAc;;AAExE,yBAAyB,WAAW;AACpC,+CAA+C,cAAc;AAC7D,+CAA+C,cAAc;AAC7D;AACA;AACA;AACA;;AAEA,4BAA4B,cAAc,EAAE;AAC5C,qBAAqB,cAAc;AACnC;;AAEA;AACA,uEAAuE,cAAc;;AAErF;AACA,sCAAsC,+BAA+B;;AAErE;AACA;AACA,gDAAgD;AAChD;AACA,OAAO;AACP;AACA;;AAEA;AACA;;AAEA;AACA,oBAAoB;AACpB;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,+BAA+B,QAAQ;;AAEvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,mBAAmB;AACzC;AACA,KAAK;;AAEL,oCAAoC,QAAQ;AAC5C;;AAEA;AACA;;AAEA,gCAAgC,OAAO;AACvC;AACA,oBAAoB;AACpB;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA,iBAAiB,OAAO;AACxB;AACA,sBAAsB;AACtB;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,oEAAoE,oCAAoC;AACxG;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrUA;AACA;AACa;;;AAGb;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,WAAW;;AAElC;AACA;AACA,2DAA2D,WAAW;;AAEtE;;AAEA;AACA,wBAAwB,WAAW;;AAEnC;AACA,qBAAqB,WAAW;;AAEhC;AACA;;AAEA;AACA;AACA;;AAEA,kDAAkD,OAAO;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,+BAA+B,cAAc;AAC7C;AACA;;AAEA;AACA,8BAA8B,cAAc;;AAE5C;AACA;AACA,gCAAgC,cAAc;AAC9C;;AAEA,mDAAmD,cAAc;AACjE;AACA,2BAA2B,cAAc;;AAEzC;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,aAAa;AACb;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,WAAW;AACX;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA,kCAAkC,aAAa;;AAE/C,uDAAuD,aAAa;AACpE;AACA,+BAA+B,OAAO;;AAEtC;;AAEA;AACA;AACA;;AAEA,gCAAgC,OAAO;AACvC;;AAEA,kCAAkC,OAAO;AACzC,mDAAmD,OAAO;;AAE1D;AACA,8BAA8B,OAAO;AACrC,kCAAkC,UAAU;AAC5C,8BAA8B,OAAO;;AAErC,mDAAmD,OAAO;AAC1D;AACA,6BAA6B,OAAO;;AAEpC;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;;AAGA,0DAA0D,oCAAoC;AAC9F","file":"js/chunk-vendors~35c1050b.805c3358.js","sourcesContent":["'use strict';\n\nmodule.exports = function emoji_html(tokens, idx /*, options, env */) {\n  return tokens[idx].content;\n};\n","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = _default;\n\nvar _clone = _interopRequireDefault(require(\"clone\"));\n\nvar _uslug = _interopRequireDefault(require(\"uslug\"));\n\nvar _token = _interopRequireDefault(require(\"markdown-it/lib/token\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction _toConsumableArray(arr) { return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _nonIterableSpread(); }\n\nfunction _nonIterableSpread() { throw new TypeError(\"Invalid attempt to spread non-iterable instance\"); }\n\nfunction _iterableToArray(iter) { if (Symbol.iterator in Object(iter) || Object.prototype.toString.call(iter) === \"[object Arguments]\") return Array.from(iter); }\n\nfunction _arrayWithoutHoles(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = new Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; var ownKeys = Object.keys(source); if (typeof Object.getOwnPropertySymbols === 'function') { ownKeys = ownKeys.concat(Object.getOwnPropertySymbols(source).filter(function (sym) { return Object.getOwnPropertyDescriptor(source, sym).enumerable; })); } ownKeys.forEach(function (key) { _defineProperty(target, key, source[key]); }); } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar TOC = \"@[toc]\";\nvar TOC_RE = /^@\\[toc\\]/im;\n\nvar markdownItSecondInstance = function markdownItSecondInstance() {};\n\nvar headingIds = {};\nvar tocHtml = \"\";\n\nvar repeat = function repeat(string, num) {\n  return new Array(num + 1).join(string);\n};\n\nvar makeSafe = function makeSafe(string, headingIds, slugifyFn) {\n  var key = slugifyFn(string); // slugify\n\n  if (!headingIds[key]) {\n    headingIds[key] = 0;\n  }\n\n  headingIds[key]++;\n  return key + (headingIds[key] > 1 ? \"-\".concat(headingIds[key]) : \"\");\n};\n\nvar space = function space() {\n  return _objectSpread({}, new _token.default(\"text\", \"\", 0), {\n    content: \" \"\n  });\n};\n\nvar renderAnchorLinkSymbol = function renderAnchorLinkSymbol(options) {\n  if (options.anchorLinkSymbolClassName) {\n    return [_objectSpread({}, new _token.default(\"span_open\", \"span\", 1), {\n      attrs: [[\"class\", options.anchorLinkSymbolClassName]]\n    }), _objectSpread({}, new _token.default(\"text\", \"\", 0), {\n      content: options.anchorLinkSymbol\n    }), new _token.default(\"span_close\", \"span\", -1)];\n  } else {\n    return [_objectSpread({}, new _token.default(\"text\", \"\", 0), {\n      content: options.anchorLinkSymbol\n    })];\n  }\n};\n\nvar renderAnchorLink = function renderAnchorLink(anchor, options, tokens, idx) {\n  var attrs = [];\n\n  if (options.anchorClassName != null) {\n    attrs.push([\"class\", options.anchorClassName]);\n  }\n\n  attrs.push([\"href\", \"#\".concat(anchor)]);\n\n  var openLinkToken = _objectSpread({}, new _token.default(\"link_open\", \"a\", 1), {\n    attrs: attrs\n  });\n\n  var closeLinkToken = new _token.default(\"link_close\", \"a\", -1);\n\n  if (options.wrapHeadingTextInAnchor) {\n    tokens[idx + 1].children.unshift(openLinkToken);\n    tokens[idx + 1].children.push(closeLinkToken);\n  } else {\n    var _tokens$children;\n\n    var linkTokens = [openLinkToken].concat(_toConsumableArray(renderAnchorLinkSymbol(options)), [closeLinkToken]); // `push` or `unshift` according to anchorLinkBefore option\n    // space is at the opposite side.\n\n    var actionOnArray = {\n      false: \"push\",\n      true: \"unshift\"\n    }; // insert space between anchor link and heading ?\n\n    if (options.anchorLinkSpace) {\n      linkTokens[actionOnArray[!options.anchorLinkBefore]](space());\n    }\n\n    (_tokens$children = tokens[idx + 1].children)[actionOnArray[options.anchorLinkBefore]].apply(_tokens$children, _toConsumableArray(linkTokens));\n  }\n};\n\nvar treeToMarkdownBulletList = function treeToMarkdownBulletList(tree) {\n  var indent = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  return tree.map(function (item) {\n    var indentation = \"  \";\n    var node = \"\".concat(repeat(indentation, indent), \"*\");\n\n    if (item.heading.content) {\n      var contentWithoutAnchor = item.heading.content.replace(/\\[([^\\]]*)\\]\\([^)]*\\)/g, \"$1\");\n      node += \" \" + \"[\".concat(contentWithoutAnchor, \"](#\").concat(item.heading.anchor, \")\\n\");\n    } else {\n      node += \"\\n\";\n    }\n\n    if (item.nodes.length) {\n      node += treeToMarkdownBulletList(item.nodes, indent + 1);\n    }\n\n    return node;\n  }).join(\"\");\n};\n\nvar generateTocMarkdownFromArray = function generateTocMarkdownFromArray(headings, options) {\n  var tree = {\n    nodes: []\n  }; // create an ast\n\n  headings.forEach(function (heading) {\n    if (heading.level < options.tocFirstLevel || heading.level > options.tocLastLevel) {\n      return;\n    }\n\n    var i = 1;\n    var lastItem = tree;\n\n    for (; i < heading.level - options.tocFirstLevel + 1; i++) {\n      if (lastItem.nodes.length === 0) {\n        lastItem.nodes.push({\n          heading: {},\n          nodes: []\n        });\n      }\n\n      lastItem = lastItem.nodes[lastItem.nodes.length - 1];\n    }\n\n    lastItem.nodes.push({\n      heading: heading,\n      nodes: []\n    });\n  });\n  return treeToMarkdownBulletList(tree.nodes);\n};\n\nfunction _default(md, options) {\n  options = _objectSpread({\n    toc: true,\n    tocClassName: \"markdownIt-TOC\",\n    tocFirstLevel: 1,\n    tocLastLevel: 6,\n    tocCallback: null,\n    anchorLink: true,\n    anchorLinkSymbol: \"#\",\n    anchorLinkBefore: true,\n    anchorClassName: \"markdownIt-Anchor\",\n    resetIds: true,\n    anchorLinkSpace: true,\n    anchorLinkSymbolClassName: null,\n    wrapHeadingTextInAnchor: false\n  }, options);\n  markdownItSecondInstance = (0, _clone.default)(md); // initialize key ids for each instance\n\n  headingIds = {};\n  md.core.ruler.push(\"init_toc\", function (state) {\n    var tokens = state.tokens; // reset key ids for each document\n\n    if (options.resetIds) {\n      headingIds = {};\n    }\n\n    var tocArray = [];\n    var tocMarkdown = \"\";\n    var tocTokens = [];\n    var slugifyFn = typeof options.slugify === \"function\" && options.slugify || _uslug.default;\n\n    for (var i = 0; i < tokens.length; i++) {\n      if (tokens[i].type !== \"heading_close\") {\n        continue;\n      }\n\n      var heading = tokens[i - 1];\n      var heading_close = tokens[i];\n\n      if (heading.type === \"inline\") {\n        var content = void 0;\n\n        if (heading.children && heading.children.length > 0 && heading.children[0].type === \"link_open\") {\n          // headings that contain links have to be processed\n          // differently since nested links aren't allowed in markdown\n          content = heading.children[1].content;\n          heading._tocAnchor = makeSafe(content, headingIds, slugifyFn);\n        } else {\n          content = heading.content;\n          heading._tocAnchor = makeSafe(heading.children.reduce(function (acc, t) {\n            return acc + t.content;\n          }, \"\"), headingIds, slugifyFn);\n        }\n\n        if (options.anchorLinkPrefix) {\n          heading._tocAnchor = options.anchorLinkPrefix + heading._tocAnchor;\n        }\n\n        tocArray.push({\n          content: content,\n          anchor: heading._tocAnchor,\n          level: +heading_close.tag.substr(1, 1)\n        });\n      }\n    }\n\n    tocMarkdown = generateTocMarkdownFromArray(tocArray, options);\n    tocTokens = markdownItSecondInstance.parse(tocMarkdown, {}); // Adding tocClassName to 'ul' element\n\n    if (_typeof(tocTokens[0]) === \"object\" && tocTokens[0].type === \"bullet_list_open\") {\n      var attrs = tocTokens[0].attrs = tocTokens[0].attrs || [];\n\n      if (options.tocClassName != null) {\n        attrs.push([\"class\", options.tocClassName]);\n      }\n    }\n\n    tocHtml = markdownItSecondInstance.renderer.render(tocTokens, markdownItSecondInstance.options);\n\n    if (typeof state.env.tocCallback === \"function\") {\n      state.env.tocCallback.call(undefined, tocMarkdown, tocArray, tocHtml);\n    } else if (typeof options.tocCallback === \"function\") {\n      options.tocCallback.call(undefined, tocMarkdown, tocArray, tocHtml);\n    } else if (typeof md.options.tocCallback === \"function\") {\n      md.options.tocCallback.call(undefined, tocMarkdown, tocArray, tocHtml);\n    }\n  });\n  md.inline.ruler.after(\"emphasis\", \"toc\", function (state, silent) {\n    var token;\n    var match;\n\n    if ( // Reject if the token does not start with @[\n    state.src.charCodeAt(state.pos) !== 0x40 || state.src.charCodeAt(state.pos + 1) !== 0x5b || // Donâ€™t run any pairs in validation mode\n    silent) {\n      return false;\n    } // Detect TOC markdown\n\n\n    match = TOC_RE.exec(state.src);\n    match = !match ? [] : match.filter(function (m) {\n      return m;\n    });\n\n    if (match.length < 1) {\n      return false;\n    } // Build content\n\n\n    token = state.push(\"toc_open\", \"toc\", 1);\n    token.markup = TOC;\n    token = state.push(\"toc_body\", \"\", 0);\n    token = state.push(\"toc_close\", \"toc\", -1); // Update pos so the parser can continue\n\n    state.pos = state.pos + 6;\n    return true;\n  });\n\n  var originalHeadingOpen = md.renderer.rules.heading_open || function () {\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    var tokens = args[0],\n        idx = args[1],\n        options = args[2],\n        self = args[4];\n    return self.renderToken(tokens, idx, options);\n  };\n\n  md.renderer.rules.heading_open = function () {\n    for (var _len2 = arguments.length, args = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {\n      args[_key2] = arguments[_key2];\n    }\n\n    var tokens = args[0],\n        idx = args[1];\n    var attrs = tokens[idx].attrs = tokens[idx].attrs || [];\n    var anchor = tokens[idx + 1]._tocAnchor;\n    attrs.push([\"id\", anchor]);\n\n    if (options.anchorLink) {\n      renderAnchorLink.apply(void 0, [anchor, options].concat(args));\n    }\n\n    return originalHeadingOpen.apply(this, args);\n  };\n\n  md.renderer.rules.toc_open = function () {\n    return \"\";\n  };\n\n  md.renderer.rules.toc_close = function () {\n    return \"\";\n  };\n\n  md.renderer.rules.toc_body = function () {\n    return \"\";\n  };\n\n  if (options.toc) {\n    md.renderer.rules.toc_body = function () {\n      return tocHtml;\n    };\n  }\n}","'use strict';\n\n\nvar emojies_defs      = require('./lib/data/full.json');\nvar emojies_shortcuts = require('./lib/data/shortcuts');\nvar emoji_html        = require('./lib/render');\nvar emoji_replace     = require('./lib/replace');\nvar normalize_opts    = require('./lib/normalize_opts');\n\n\nmodule.exports = function emoji_plugin(md, options) {\n  var defaults = {\n    defs: emojies_defs,\n    shortcuts: emojies_shortcuts,\n    enabled: []\n  };\n\n  var opts = normalize_opts(md.utils.assign({}, defaults, options || {}));\n\n  md.renderer.rules.emoji = emoji_html;\n\n  md.core.ruler.push('emoji', emoji_replace(md, opts.defs, opts.shortcuts, opts.scanRE, opts.replaceRE));\n};\n","// Convert input options to more useable format\n// and compile search regexp\n\n'use strict';\n\n\nfunction quoteRE(str) {\n  return str.replace(/[.?*+^$[\\]\\\\(){}|-]/g, '\\\\$&');\n}\n\n\nmodule.exports = function normalize_opts(options) {\n  var emojies = options.defs,\n      shortcuts;\n\n  // Filter emojies by whitelist, if needed\n  if (options.enabled.length) {\n    emojies = Object.keys(emojies).reduce(function (acc, key) {\n      if (options.enabled.indexOf(key) >= 0) {\n        acc[key] = emojies[key];\n      }\n      return acc;\n    }, {});\n  }\n\n  // Flatten shortcuts to simple object: { alias: emoji_name }\n  shortcuts = Object.keys(options.shortcuts).reduce(function (acc, key) {\n    // Skip aliases for filtered emojies, to reduce regexp\n    if (!emojies[key]) { return acc; }\n\n    if (Array.isArray(options.shortcuts[key])) {\n      options.shortcuts[key].forEach(function (alias) {\n        acc[alias] = key;\n      });\n      return acc;\n    }\n\n    acc[options.shortcuts[key]] = key;\n    return acc;\n  }, {});\n\n  // Compile regexp\n  var names = Object.keys(emojies)\n                .map(function (name) { return ':' + name + ':'; })\n                .concat(Object.keys(shortcuts))\n                .sort()\n                .reverse()\n                .map(function (name) { return quoteRE(name); })\n                .join('|');\n  var scanRE = RegExp(names);\n  var replaceRE = RegExp(names, 'g');\n\n  return {\n    defs: emojies,\n    shortcuts: shortcuts,\n    scanRE: scanRE,\n    replaceRE: replaceRE\n  };\n};\n","// Emojies & shortcuts replacement logic.\n//\n// Note: In theory, it could be faster to parse :smile: in inline chain and\n// leave only shortcuts here. But, who care...\n//\n\n'use strict';\n\n\nmodule.exports = function create_rule(md, emojies, shortcuts, scanRE, replaceRE) {\n  var arrayReplaceAt = md.utils.arrayReplaceAt,\n      ucm = md.utils.lib.ucmicro,\n      ZPCc = new RegExp([ ucm.Z.source, ucm.P.source, ucm.Cc.source ].join('|'));\n\n  function splitTextToken(text, level, Token) {\n    var token, last_pos = 0, nodes = [];\n\n    text.replace(replaceRE, function (match, offset, src) {\n      var emoji_name;\n      // Validate emoji name\n      if (shortcuts.hasOwnProperty(match)) {\n        // replace shortcut with full name\n        emoji_name = shortcuts[match];\n\n        // Don't allow letters before any shortcut (as in no \":/\" in http://)\n        if (offset > 0 && !ZPCc.test(src[offset - 1])) {\n          return;\n        }\n\n        // Don't allow letters after any shortcut\n        if (offset + match.length < src.length && !ZPCc.test(src[offset + match.length])) {\n          return;\n        }\n      } else {\n        emoji_name = match.slice(1, -1);\n      }\n\n      // Add new tokens to pending list\n      if (offset > last_pos) {\n        token         = new Token('text', '', 0);\n        token.content = text.slice(last_pos, offset);\n        nodes.push(token);\n      }\n\n      token         = new Token('emoji', '', 0);\n      token.markup  = emoji_name;\n      token.content = emojies[emoji_name];\n      nodes.push(token);\n\n      last_pos = offset + match.length;\n    });\n\n    if (last_pos < text.length) {\n      token         = new Token('text', '', 0);\n      token.content = text.slice(last_pos);\n      nodes.push(token);\n    }\n\n    return nodes;\n  }\n\n  return function emoji_replace(state) {\n    var i, j, l, tokens, token,\n        blockTokens = state.tokens,\n        autolinkLevel = 0;\n\n    for (j = 0, l = blockTokens.length; j < l; j++) {\n      if (blockTokens[j].type !== 'inline') { continue; }\n      tokens = blockTokens[j].children;\n\n      // We scan from the end, to keep position when new tags added.\n      // Use reversed logic in links start/end match\n      for (i = tokens.length - 1; i >= 0; i--) {\n        token = tokens[i];\n\n        if (token.type === 'link_open' || token.type === 'link_close') {\n          if (token.info === 'auto') { autolinkLevel -= token.nesting; }\n        }\n\n        if (token.type === 'text' && autolinkLevel === 0 && scanRE.test(token.content)) {\n          // replace current node\n          blockTokens[j].children = tokens = arrayReplaceAt(\n            tokens, i, splitTextToken(token.content, token.level, state.Token)\n          );\n        }\n      }\n    }\n  };\n};\n","'use strict';\n\n\nmodule.exports = function ins_plugin(md) {\n  // Insert each marker as a separate text token, and add it to delimiter list\n  //\n  function tokenize(state, silent) {\n    var i, scanned, token, len, ch,\n        start = state.pos,\n        marker = state.src.charCodeAt(start);\n\n    if (silent) { return false; }\n\n    if (marker !== 0x3D/* = */) { return false; }\n\n    scanned = state.scanDelims(state.pos, true);\n    len = scanned.length;\n    ch = String.fromCharCode(marker);\n\n    if (len < 2) { return false; }\n\n    if (len % 2) {\n      token         = state.push('text', '', 0);\n      token.content = ch;\n      len--;\n    }\n\n    for (i = 0; i < len; i += 2) {\n      token         = state.push('text', '', 0);\n      token.content = ch + ch;\n\n      state.delimiters.push({\n        marker: marker,\n        jump:   i,\n        token:  state.tokens.length - 1,\n        level:  state.level,\n        end:    -1,\n        open:   scanned.can_open,\n        close:  scanned.can_close\n      });\n    }\n\n    state.pos += scanned.length;\n\n    return true;\n  }\n\n\n  // Walk through delimiter list and replace text tokens with tags\n  //\n  function postProcess(state) {\n    var i, j,\n        startDelim,\n        endDelim,\n        token,\n        loneMarkers = [],\n        delimiters = state.delimiters,\n        max = state.delimiters.length;\n\n    for (i = 0; i < max; i++) {\n      startDelim = delimiters[i];\n\n      if (startDelim.marker !== 0x3D/* = */) {\n        continue;\n      }\n\n      if (startDelim.end === -1) {\n        continue;\n      }\n\n      endDelim = delimiters[startDelim.end];\n\n      token         = state.tokens[startDelim.token];\n      token.type    = 'mark_open';\n      token.tag     = 'mark';\n      token.nesting = 1;\n      token.markup  = '==';\n      token.content = '';\n\n      token         = state.tokens[endDelim.token];\n      token.type    = 'mark_close';\n      token.tag     = 'mark';\n      token.nesting = -1;\n      token.markup  = '==';\n      token.content = '';\n\n      if (state.tokens[endDelim.token - 1].type === 'text' &&\n          state.tokens[endDelim.token - 1].content === '=') {\n\n        loneMarkers.push(endDelim.token - 1);\n      }\n    }\n\n    // If a marker sequence has an odd number of characters, it's splitted\n    // like this: `~~~~~` -> `~` + `~~` + `~~`, leaving one marker at the\n    // start of the sequence.\n    //\n    // So, we have to move all those markers after subsequent s_close tags.\n    //\n    while (loneMarkers.length) {\n      i = loneMarkers.pop();\n      j = i + 1;\n\n      while (j < state.tokens.length && state.tokens[j].type === 'mark_close') {\n        j++;\n      }\n\n      j--;\n\n      if (i !== j) {\n        token = state.tokens[j];\n        state.tokens[j] = state.tokens[i];\n        state.tokens[i] = token;\n      }\n    }\n  }\n\n  md.inline.ruler.before('emphasis', 'mark', tokenize);\n  md.inline.ruler2.before('emphasis', 'mark', postProcess);\n};\n","// Enclose abbreviations in <abbr> tags\n//\n'use strict';\n\n\nmodule.exports = function sub_plugin(md) {\n  var escapeRE        = md.utils.escapeRE,\n      arrayReplaceAt  = md.utils.arrayReplaceAt;\n\n  // ASCII characters in Cc, Sc, Sm, Sk categories we should terminate on;\n  // you can check character classes here:\n  // http://www.unicode.org/Public/UNIDATA/UnicodeData.txt\n  var OTHER_CHARS      = ' \\r\\n$+<=>^`|~';\n\n  var UNICODE_PUNCT_RE = md.utils.lib.ucmicro.P.source;\n  var UNICODE_SPACE_RE = md.utils.lib.ucmicro.Z.source;\n\n\n  function abbr_def(state, startLine, endLine, silent) {\n    var label, title, ch, labelStart, labelEnd,\n        pos = state.bMarks[startLine] + state.tShift[startLine],\n        max = state.eMarks[startLine];\n\n    if (pos + 2 >= max) { return false; }\n\n    if (state.src.charCodeAt(pos++) !== 0x2A/* * */) { return false; }\n    if (state.src.charCodeAt(pos++) !== 0x5B/* [ */) { return false; }\n\n    labelStart = pos;\n\n    for (; pos < max; pos++) {\n      ch = state.src.charCodeAt(pos);\n      if (ch === 0x5B /* [ */) {\n        return false;\n      } else if (ch === 0x5D /* ] */) {\n        labelEnd = pos;\n        break;\n      } else if (ch === 0x5C /* \\ */) {\n        pos++;\n      }\n    }\n\n    if (labelEnd < 0 || state.src.charCodeAt(labelEnd + 1) !== 0x3A/* : */) {\n      return false;\n    }\n\n    if (silent) { return true; }\n\n    label = state.src.slice(labelStart, labelEnd).replace(/\\\\(.)/g, '$1');\n    title = state.src.slice(labelEnd + 2, max).trim();\n    if (label.length === 0) { return false; }\n    if (title.length === 0) { return false; }\n    if (!state.env.abbreviations) { state.env.abbreviations = {}; }\n    // prepend ':' to avoid conflict with Object.prototype members\n    if (typeof state.env.abbreviations[':' + label] === 'undefined') {\n      state.env.abbreviations[':' + label] = title;\n    }\n\n    state.line = startLine + 1;\n    return true;\n  }\n\n\n  function abbr_replace(state) {\n    var i, j, l, tokens, token, text, nodes, pos, reg, m, regText, regSimple,\n        currentToken,\n        blockTokens = state.tokens;\n\n    if (!state.env.abbreviations) { return; }\n\n    regSimple = new RegExp('(?:' +\n      Object.keys(state.env.abbreviations).map(function (x) {\n        return x.substr(1);\n      }).sort(function (a, b) {\n        return b.length - a.length;\n      }).map(escapeRE).join('|') +\n    ')');\n\n    regText = '(^|' + UNICODE_PUNCT_RE + '|' + UNICODE_SPACE_RE +\n                    '|[' + OTHER_CHARS.split('').map(escapeRE).join('') + '])'\n            + '(' + Object.keys(state.env.abbreviations).map(function (x) {\n                      return x.substr(1);\n                    }).sort(function (a, b) {\n                      return b.length - a.length;\n                    }).map(escapeRE).join('|') + ')'\n            + '($|' + UNICODE_PUNCT_RE + '|' + UNICODE_SPACE_RE +\n                    '|[' + OTHER_CHARS.split('').map(escapeRE).join('') + '])';\n\n    reg = new RegExp(regText, 'g');\n\n    for (j = 0, l = blockTokens.length; j < l; j++) {\n      if (blockTokens[j].type !== 'inline') { continue; }\n      tokens = blockTokens[j].children;\n\n      // We scan from the end, to keep position when new tags added.\n      for (i = tokens.length - 1; i >= 0; i--) {\n        currentToken = tokens[i];\n        if (currentToken.type !== 'text') { continue; }\n\n        pos = 0;\n        text = currentToken.content;\n        reg.lastIndex = 0;\n        nodes = [];\n\n        // fast regexp run to determine whether there are any abbreviated words\n        // in the current token\n        if (!regSimple.test(text)) { continue; }\n\n        while ((m = reg.exec(text))) {\n          if (m.index > 0 || m[1].length > 0) {\n            token         = new state.Token('text', '', 0);\n            token.content = text.slice(pos, m.index + m[1].length);\n            nodes.push(token);\n          }\n\n          token         = new state.Token('abbr_open', 'abbr', 1);\n          token.attrs   = [ [ 'title', state.env.abbreviations[':' + m[2]] ] ];\n          nodes.push(token);\n\n          token         = new state.Token('text', '', 0);\n          token.content = m[2];\n          nodes.push(token);\n\n          token         = new state.Token('abbr_close', 'abbr', -1);\n          nodes.push(token);\n\n          reg.lastIndex -= m[3].length;\n          pos = reg.lastIndex;\n        }\n\n        if (!nodes.length) { continue; }\n\n        if (pos < text.length) {\n          token         = new state.Token('text', '', 0);\n          token.content = text.slice(pos);\n          nodes.push(token);\n        }\n\n        // replace current node\n        blockTokens[j].children = tokens = arrayReplaceAt(tokens, i, nodes);\n      }\n    }\n  }\n\n  md.block.ruler.before('reference', 'abbr_def', abbr_def, { alt: [ 'paragraph', 'reference' ] });\n\n  md.core.ruler.after('linkify', 'abbr_replace', abbr_replace);\n};\n","// Process ~subscript~\n\n'use strict';\n\n// same as UNESCAPE_MD_RE plus a space\nvar UNESCAPE_RE = /\\\\([ \\\\!\"#$%&'()*+,.\\/:;<=>?@[\\]^_`{|}~-])/g;\n\n\nfunction subscript(state, silent) {\n  var found,\n      content,\n      token,\n      max = state.posMax,\n      start = state.pos;\n\n  if (state.src.charCodeAt(start) !== 0x7E/* ~ */) { return false; }\n  if (silent) { return false; } // don't run any pairs in validation mode\n  if (start + 2 >= max) { return false; }\n\n  state.pos = start + 1;\n\n  while (state.pos < max) {\n    if (state.src.charCodeAt(state.pos) === 0x7E/* ~ */) {\n      found = true;\n      break;\n    }\n\n    state.md.inline.skipToken(state);\n  }\n\n  if (!found || start + 1 === state.pos) {\n    state.pos = start;\n    return false;\n  }\n\n  content = state.src.slice(start + 1, state.pos);\n\n  // don't allow unescaped spaces/newlines inside\n  if (content.match(/(^|[^\\\\])(\\\\\\\\)*\\s/)) {\n    state.pos = start;\n    return false;\n  }\n\n  // found!\n  state.posMax = state.pos;\n  state.pos = start + 1;\n\n  // Earlier we checked !silent, but this implementation does not need it\n  token         = state.push('sub_open', 'sub', 1);\n  token.markup  = '~';\n\n  token         = state.push('text', '', 0);\n  token.content = content.replace(UNESCAPE_RE, '$1');\n\n  token         = state.push('sub_close', 'sub', -1);\n  token.markup  = '~';\n\n  state.pos = state.posMax + 1;\n  state.posMax = max;\n  return true;\n}\n\n\nmodule.exports = function sub_plugin(md) {\n  md.inline.ruler.after('emphasis', 'sub', subscript);\n};\n","// Process ^superscript^\n\n'use strict';\n\n// same as UNESCAPE_MD_RE plus a space\nvar UNESCAPE_RE = /\\\\([ \\\\!\"#$%&'()*+,.\\/:;<=>?@[\\]^_`{|}~-])/g;\n\nfunction superscript(state, silent) {\n  var found,\n      content,\n      token,\n      max = state.posMax,\n      start = state.pos;\n\n  if (state.src.charCodeAt(start) !== 0x5E/* ^ */) { return false; }\n  if (silent) { return false; } // don't run any pairs in validation mode\n  if (start + 2 >= max) { return false; }\n\n  state.pos = start + 1;\n\n  while (state.pos < max) {\n    if (state.src.charCodeAt(state.pos) === 0x5E/* ^ */) {\n      found = true;\n      break;\n    }\n\n    state.md.inline.skipToken(state);\n  }\n\n  if (!found || start + 1 === state.pos) {\n    state.pos = start;\n    return false;\n  }\n\n  content = state.src.slice(start + 1, state.pos);\n\n  // don't allow unescaped spaces/newlines inside\n  if (content.match(/(^|[^\\\\])(\\\\\\\\)*\\s/)) {\n    state.pos = start;\n    return false;\n  }\n\n  // found!\n  state.posMax = state.pos;\n  state.pos = start + 1;\n\n  // Earlier we checked !silent, but this implementation does not need it\n  token         = state.push('sup_open', 'sup', 1);\n  token.markup  = '^';\n\n  token         = state.push('text', '', 0);\n  token.content = content.replace(UNESCAPE_RE, '$1');\n\n  token         = state.push('sup_close', 'sup', -1);\n  token.markup  = '^';\n\n  state.pos = state.posMax + 1;\n  state.posMax = max;\n  return true;\n}\n\n\nmodule.exports = function sup_plugin(md) {\n  md.inline.ruler.after('emphasis', 'sup', superscript);\n};\n","/* Process inline math */\n/*\nLike markdown-it-simplemath, this is a stripped down, simplified version of:\nhttps://github.com/runarberg/markdown-it-math\n\nIt differs in that it takes (a subset of) LaTeX as input and relies on KaTeX\nfor rendering output.\n*/\n\n/*jslint node: true */\n'use strict';\n\nvar katex = require('katex');\n\n// Test if potential opening or closing delimieter\n// Assumes that there is a \"$\" at state.src[pos]\nfunction isValidDelim(state, pos) {\n    var prevChar, nextChar,\n        max = state.posMax,\n        can_open = true,\n        can_close = true;\n\n    prevChar = pos > 0 ? state.src.charCodeAt(pos - 1) : -1;\n    nextChar = pos + 1 <= max ? state.src.charCodeAt(pos + 1) : -1;\n\n    // Check non-whitespace conditions for opening and closing, and\n    // check that closing delimeter isn't followed by a number\n    if (prevChar === 0x20/* \" \" */ || prevChar === 0x09/* \\t */ ||\n            (nextChar >= 0x30/* \"0\" */ && nextChar <= 0x39/* \"9\" */)) {\n        can_close = false;\n    }\n    if (nextChar === 0x20/* \" \" */ || nextChar === 0x09/* \\t */) {\n        can_open = false;\n    }\n\n    return {\n        can_open: can_open,\n        can_close: can_close\n    };\n}\n\nfunction math_inline(state, silent) {\n    var start, match, token, res, pos, esc_count;\n\n    if (state.src[state.pos] !== \"$\") { return false; }\n\n    res = isValidDelim(state, state.pos);\n    if (!res.can_open) {\n        if (!silent) { state.pending += \"$\"; }\n        state.pos += 1;\n        return true;\n    }\n\n    // First check for and bypass all properly escaped delimieters\n    // This loop will assume that the first leading backtick can not\n    // be the first character in state.src, which is known since\n    // we have found an opening delimieter already.\n    start = state.pos + 1;\n    match = start;\n    while ( (match = state.src.indexOf(\"$\", match)) !== -1) {\n        // Found potential $, look for escapes, pos will point to\n        // first non escape when complete\n        pos = match - 1;\n        while (state.src[pos] === \"\\\\\") { pos -= 1; }\n\n        // Even number of escapes, potential closing delimiter found\n        if ( ((match - pos) % 2) == 1 ) { break; }\n        match += 1;\n    }\n\n    // No closing delimter found.  Consume $ and continue.\n    if (match === -1) {\n        if (!silent) { state.pending += \"$\"; }\n        state.pos = start;\n        return true;\n    }\n\n    // Check if we have empty content, ie: $$.  Do not parse.\n    if (match - start === 0) {\n        if (!silent) { state.pending += \"$$\"; }\n        state.pos = start + 1;\n        return true;\n    }\n\n    // Check for valid closing delimiter\n    res = isValidDelim(state, match);\n    if (!res.can_close) {\n        if (!silent) { state.pending += \"$\"; }\n        state.pos = start;\n        return true;\n    }\n\n    if (!silent) {\n        token         = state.push('math_inline', 'math', 0);\n        token.markup  = \"$\";\n        token.content = state.src.slice(start, match);\n    }\n\n    state.pos = match + 1;\n    return true;\n}\n\nfunction math_block(state, start, end, silent){\n    var firstLine, lastLine, next, lastPos, found = false, token,\n        pos = state.bMarks[start] + state.tShift[start],\n        max = state.eMarks[start]\n\n    if(pos + 2 > max){ return false; }\n    if(state.src.slice(pos,pos+2)!=='$$'){ return false; }\n\n    pos += 2;\n    firstLine = state.src.slice(pos,max);\n\n    if(silent){ return true; }\n    if(firstLine.trim().slice(-2)==='$$'){\n        // Single line expression\n        firstLine = firstLine.trim().slice(0, -2);\n        found = true;\n    }\n\n    for(next = start; !found; ){\n\n        next++;\n\n        if(next >= end){ break; }\n\n        pos = state.bMarks[next]+state.tShift[next];\n        max = state.eMarks[next];\n\n        if(pos < max && state.tShift[next] < state.blkIndent){\n            // non-empty line with negative indent should stop the list:\n            break;\n        }\n\n        if(state.src.slice(pos,max).trim().slice(-2)==='$$'){\n            lastPos = state.src.slice(0,max).lastIndexOf('$$');\n            lastLine = state.src.slice(pos,lastPos);\n            found = true;\n        }\n\n    }\n\n    state.line = next + 1;\n\n    token = state.push('math_block', 'math', 0);\n    token.block = true;\n    token.content = (firstLine && firstLine.trim() ? firstLine + '\\n' : '')\n    + state.getLines(start + 1, next, state.tShift[start], true)\n    + (lastLine && lastLine.trim() ? lastLine : '');\n    token.map = [ start, state.line ];\n    token.markup = '$$';\n    return true;\n}\n\nmodule.exports = function math_plugin(md, options) {\n    // Default options\n\n    options = options || {};\n\n    // set KaTeX as the renderer for markdown-it-simplemath\n    var katexInline = function(latex){\n        options.displayMode = false;\n        try{\n            return katex.renderToString(latex, options);\n        }\n        catch(error){\n            if(options.throwOnError){ console.log(error); }\n            return latex;\n        }\n    };\n\n    var inlineRenderer = function(tokens, idx){\n        return katexInline(tokens[idx].content);\n    };\n\n    var katexBlock = function(latex){\n        options.displayMode = true;\n        try{\n            return \"<p>\" + katex.renderToString(latex, options) + \"</p>\";\n        }\n        catch(error){\n            if(options.throwOnError){ console.log(error); }\n            return latex;\n        }\n    }\n\n    var blockRenderer = function(tokens, idx){\n        return  katexBlock(tokens[idx].content) + '\\n';\n    }\n\n    md.inline.ruler.after('escape', 'math_inline', math_inline);\n    md.block.ruler.after('blockquote', 'math_block', math_block, {\n        alt: [ 'paragraph', 'reference', 'blockquote', 'list' ]\n    });\n    md.renderer.rules.math_inline = inlineRenderer;\n    md.renderer.rules.math_block = blockRenderer;\n};\n","// Emoticons -> Emoji mapping.\n//\n// (!) Some patterns skipped, to avoid collisions\n// without increase matcher complicity. Than can change in future.\n//\n// Places to look for more emoticons info:\n//\n// - http://en.wikipedia.org/wiki/List_of_emoticons#Western\n// - https://github.com/wooorm/emoticon/blob/master/Support.md\n// - http://factoryjoe.com/projects/emoticons/\n//\n'use strict';\n\nmodule.exports = {\n  angry:            [ '>:(', '>:-(' ],\n  blush:            [ ':\")', ':-\")' ],\n  broken_heart:     [ '</3', '<\\\\3' ],\n  // :\\ and :-\\ not used because of conflict with markdown escaping\n  confused:         [ ':/', ':-/' ], // twemoji shows question\n  cry:              [ \":'(\", \":'-(\", ':,(', ':,-(' ],\n  frowning:         [ ':(', ':-(' ],\n  heart:            [ '<3' ],\n  imp:              [ ']:(', ']:-(' ],\n  innocent:         [ 'o:)', 'O:)', 'o:-)', 'O:-)', '0:)', '0:-)' ],\n  joy:              [ \":')\", \":'-)\", ':,)', ':,-)', \":'D\", \":'-D\", ':,D', ':,-D' ],\n  kissing:          [ ':*', ':-*' ],\n  laughing:         [ 'x-)', 'X-)' ],\n  neutral_face:     [ ':|', ':-|' ],\n  open_mouth:       [ ':o', ':-o', ':O', ':-O' ],\n  rage:             [ ':@', ':-@' ],\n  smile:            [ ':D', ':-D' ],\n  smiley:           [ ':)', ':-)' ],\n  smiling_imp:      [ ']:)', ']:-)' ],\n  sob:              [ \":,'(\", \":,'-(\", ';(', ';-(' ],\n  stuck_out_tongue: [ ':P', ':-P' ],\n  sunglasses:       [ '8-)', 'B-)' ],\n  sweat:            [ ',:(', ',:-(' ],\n  sweat_smile:      [ ',:)', ',:-)' ],\n  unamused:         [ ':s', ':-S', ':z', ':-Z', ':$', ':-$' ],\n  wink:             [ ';)', ';-)' ]\n};\n","// Markdown-it plugin to render GitHub-style task lists; see\n//\n// https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments\n// https://github.com/blog/1825-task-lists-in-all-markdown-documents\n\nvar disableCheckboxes = true;\nvar useLabelWrapper = false;\nvar useLabelAfter = false;\n\nmodule.exports = function(md, options) {\n\tif (options) {\n\t\tdisableCheckboxes = !options.enabled;\n\t\tuseLabelWrapper = !!options.label;\n\t\tuseLabelAfter = !!options.labelAfter;\n\t}\n\n\tmd.core.ruler.after('inline', 'github-task-lists', function(state) {\n\t\tvar tokens = state.tokens;\n\t\tfor (var i = 2; i < tokens.length; i++) {\n\t\t\tif (isTodoItem(tokens, i)) {\n\t\t\t\ttodoify(tokens[i], state.Token);\n\t\t\t\tattrSet(tokens[i-2], 'class', 'task-list-item' + (!disableCheckboxes ? ' enabled' : ''));\n\t\t\t\tattrSet(tokens[parentToken(tokens, i-2)], 'class', 'contains-task-list');\n\t\t\t}\n\t\t}\n\t});\n};\n\nfunction attrSet(token, name, value) {\n\tvar index = token.attrIndex(name);\n\tvar attr = [name, value];\n\n\tif (index < 0) {\n\t\ttoken.attrPush(attr);\n\t} else {\n\t\ttoken.attrs[index] = attr;\n\t}\n}\n\nfunction parentToken(tokens, index) {\n\tvar targetLevel = tokens[index].level - 1;\n\tfor (var i = index - 1; i >= 0; i--) {\n\t\tif (tokens[i].level === targetLevel) {\n\t\t\treturn i;\n\t\t}\n\t}\n\treturn -1;\n}\n\nfunction isTodoItem(tokens, index) {\n\treturn isInline(tokens[index]) &&\n\t       isParagraph(tokens[index - 1]) &&\n\t       isListItem(tokens[index - 2]) &&\n\t       startsWithTodoMarkdown(tokens[index]);\n}\n\nfunction todoify(token, TokenConstructor) {\n\ttoken.children.unshift(makeCheckbox(token, TokenConstructor));\n\ttoken.children[1].content = token.children[1].content.slice(3);\n\ttoken.content = token.content.slice(3);\n\n\tif (useLabelWrapper) {\n\t\tif (useLabelAfter) {\n\t\t\ttoken.children.pop();\n\n\t\t\t// Use large random number as id property of the checkbox.\n\t\t\tvar id = 'task-item-' + Math.ceil(Math.random() * (10000 * 1000) - 1000);\n\t\t\ttoken.children[0].content = token.children[0].content.slice(0, -1) + ' id=\"' + id + '\">';\n\t\t\ttoken.children.push(afterLabel(token.content, id, TokenConstructor));\n\t\t} else {\n\t\t\ttoken.children.unshift(beginLabel(TokenConstructor));\n\t\t\ttoken.children.push(endLabel(TokenConstructor));\n\t\t}\n\t}\n}\n\nfunction makeCheckbox(token, TokenConstructor) {\n\tvar checkbox = new TokenConstructor('html_inline', '', 0);\n\tvar disabledAttr = disableCheckboxes ? ' disabled=\"\" ' : '';\n\tif (token.content.indexOf('[ ] ') === 0) {\n\t\tcheckbox.content = '<input class=\"task-list-item-checkbox\"' + disabledAttr + 'type=\"checkbox\">';\n\t} else if (token.content.indexOf('[x] ') === 0 || token.content.indexOf('[X] ') === 0) {\n\t\tcheckbox.content = '<input class=\"task-list-item-checkbox\" checked=\"\"' + disabledAttr + 'type=\"checkbox\">';\n\t}\n\treturn checkbox;\n}\n\n// these next two functions are kind of hacky; probably should really be a\n// true block-level token with .tag=='label'\nfunction beginLabel(TokenConstructor) {\n\tvar token = new TokenConstructor('html_inline', '', 0);\n\ttoken.content = '<label>';\n\treturn token;\n}\n\nfunction endLabel(TokenConstructor) {\n\tvar token = new TokenConstructor('html_inline', '', 0);\n\ttoken.content = '</label>';\n\treturn token;\n}\n\nfunction afterLabel(content, id, TokenConstructor) {\n\tvar token = new TokenConstructor('html_inline', '', 0);\n\ttoken.content = '<label class=\"task-list-item-label\" for=\"' + id + '\">' + content + '</label>';\n\ttoken.attrs = [{for: id}];\n\treturn token;\n}\n\nfunction isInline(token) { return token.type === 'inline'; }\nfunction isParagraph(token) { return token.type === 'paragraph_open'; }\nfunction isListItem(token) { return token.type === 'list_item_open'; }\n\nfunction startsWithTodoMarkdown(token) {\n\t// leading whitespace in a list item is already trimmed off by markdown-it\n\treturn token.content.indexOf('[ ] ') === 0 || token.content.indexOf('[x] ') === 0 || token.content.indexOf('[X] ') === 0;\n}\n","'use strict';\n\n\nmodule.exports = function ins_plugin(md) {\n  // Insert each marker as a separate text token, and add it to delimiter list\n  //\n  function tokenize(state, silent) {\n    var i, scanned, token, len, ch,\n        start = state.pos,\n        marker = state.src.charCodeAt(start);\n\n    if (silent) { return false; }\n\n    if (marker !== 0x2B/* + */) { return false; }\n\n    scanned = state.scanDelims(state.pos, true);\n    len = scanned.length;\n    ch = String.fromCharCode(marker);\n\n    if (len < 2) { return false; }\n\n    if (len % 2) {\n      token         = state.push('text', '', 0);\n      token.content = ch;\n      len--;\n    }\n\n    for (i = 0; i < len; i += 2) {\n      token         = state.push('text', '', 0);\n      token.content = ch + ch;\n\n      state.delimiters.push({\n        marker: marker,\n        jump:   i,\n        token:  state.tokens.length - 1,\n        level:  state.level,\n        end:    -1,\n        open:   scanned.can_open,\n        close:  scanned.can_close\n      });\n    }\n\n    state.pos += scanned.length;\n\n    return true;\n  }\n\n\n  // Walk through delimiter list and replace text tokens with tags\n  //\n  function postProcess(state) {\n    var i, j,\n        startDelim,\n        endDelim,\n        token,\n        loneMarkers = [],\n        delimiters = state.delimiters,\n        max = state.delimiters.length;\n\n    for (i = 0; i < max; i++) {\n      startDelim = delimiters[i];\n\n      if (startDelim.marker !== 0x2B/* + */) {\n        continue;\n      }\n\n      if (startDelim.end === -1) {\n        continue;\n      }\n\n      endDelim = delimiters[startDelim.end];\n\n      token         = state.tokens[startDelim.token];\n      token.type    = 'ins_open';\n      token.tag     = 'ins';\n      token.nesting = 1;\n      token.markup  = '++';\n      token.content = '';\n\n      token         = state.tokens[endDelim.token];\n      token.type    = 'ins_close';\n      token.tag     = 'ins';\n      token.nesting = -1;\n      token.markup  = '++';\n      token.content = '';\n\n      if (state.tokens[endDelim.token - 1].type === 'text' &&\n          state.tokens[endDelim.token - 1].content === '+') {\n\n        loneMarkers.push(endDelim.token - 1);\n      }\n    }\n\n    // If a marker sequence has an odd number of characters, it's splitted\n    // like this: `~~~~~` -> `~` + `~~` + `~~`, leaving one marker at the\n    // start of the sequence.\n    //\n    // So, we have to move all those markers after subsequent s_close tags.\n    //\n    while (loneMarkers.length) {\n      i = loneMarkers.pop();\n      j = i + 1;\n\n      while (j < state.tokens.length && state.tokens[j].type === 'ins_close') {\n        j++;\n      }\n\n      j--;\n\n      if (i !== j) {\n        token = state.tokens[j];\n        state.tokens[j] = state.tokens[i];\n        state.tokens[i] = token;\n      }\n    }\n  }\n\n  md.inline.ruler.before('emphasis', 'ins', tokenize);\n  md.inline.ruler2.before('emphasis', 'ins', postProcess);\n};\n","// Process footnotes\n//\n'use strict';\n\n////////////////////////////////////////////////////////////////////////////////\n// Renderer partials\n\nfunction _footnote_ref(tokens, idx) {\n  var n = Number(tokens[idx].meta.id + 1).toString();\n  var id = 'fnref' + n;\n  if (tokens[idx].meta.subId > 0) {\n    id += ':' + tokens[idx].meta.subId;\n  }\n  return '<sup class=\"footnote-ref\"><a href=\"#fn' + n + '\" id=\"' + id + '\">[' + n + ']</a></sup>';\n}\nfunction _footnote_block_open(tokens, idx, options) {\n  return (options.xhtmlOut ? '<hr class=\"footnotes-sep\" />\\n' : '<hr class=\"footnotes-sep\">\\n') +\n         '<section class=\"footnotes\">\\n' +\n         '<ol class=\"footnotes-list\">\\n';\n}\nfunction _footnote_block_close() {\n  return '</ol>\\n</section>\\n';\n}\nfunction _footnote_open(tokens, idx) {\n  var id = Number(tokens[idx].meta.id + 1).toString();\n  return '<li id=\"fn' + id + '\"  class=\"footnote-item\">';\n}\nfunction _footnote_close() {\n  return '</li>\\n';\n}\nfunction _footnote_anchor(tokens, idx) {\n  var n = Number(tokens[idx].meta.id + 1).toString();\n  var id = 'fnref' + n;\n  if (tokens[idx].meta.subId > 0) {\n    id += ':' + tokens[idx].meta.subId;\n  }\n  return ' <a href=\"#' + id + '\" class=\"footnote-backref\">\\u21a9</a>'; /* â†© */\n}\n\n////////////////////////////////////////////////////////////////////////////////\n\n\nmodule.exports = function sub_plugin(md) {\n  var parseLinkLabel = md.helpers.parseLinkLabel,\n      isSpace = md.utils.isSpace;\n\n  md.renderer.rules.footnote_ref          = _footnote_ref;\n  md.renderer.rules.footnote_block_open   = _footnote_block_open;\n  md.renderer.rules.footnote_block_close  = _footnote_block_close;\n  md.renderer.rules.footnote_open         = _footnote_open;\n  md.renderer.rules.footnote_close        = _footnote_close;\n  md.renderer.rules.footnote_anchor       = _footnote_anchor;\n\n  // Process footnote block definition\n  function footnote_def(state, startLine, endLine, silent) {\n    var oldBMark, oldTShift, oldSCount, oldParentType, pos, label, token,\n        initial, offset, ch, posAfterColon,\n        start = state.bMarks[startLine] + state.tShift[startLine],\n        max = state.eMarks[startLine];\n\n    // line should be at least 5 chars - \"[^x]:\"\n    if (start + 4 > max) { return false; }\n\n    if (state.src.charCodeAt(start) !== 0x5B/* [ */) { return false; }\n    if (state.src.charCodeAt(start + 1) !== 0x5E/* ^ */) { return false; }\n\n    for (pos = start + 2; pos < max; pos++) {\n      if (state.src.charCodeAt(pos) === 0x20) { return false; }\n      if (state.src.charCodeAt(pos) === 0x5D /* ] */) {\n        break;\n      }\n    }\n\n    if (pos === start + 2) { return false; } // no empty footnote labels\n    if (pos + 1 >= max || state.src.charCodeAt(++pos) !== 0x3A /* : */) { return false; }\n    if (silent) { return true; }\n    pos++;\n\n    if (!state.env.footnotes) { state.env.footnotes = {}; }\n    if (!state.env.footnotes.refs) { state.env.footnotes.refs = {}; }\n    label = state.src.slice(start + 2, pos - 2);\n    state.env.footnotes.refs[':' + label] = -1;\n\n    token       = new state.Token('footnote_reference_open', '', 1);\n    token.meta  = { label: label };\n    token.level = state.level++;\n    state.tokens.push(token);\n\n    oldBMark = state.bMarks[startLine];\n    oldTShift = state.tShift[startLine];\n    oldSCount = state.sCount[startLine];\n    oldParentType = state.parentType;\n\n    posAfterColon = pos;\n    initial = offset = state.sCount[startLine] + pos - (state.bMarks[startLine] + state.tShift[startLine]);\n\n    while (pos < max) {\n      ch = state.src.charCodeAt(pos);\n\n      if (isSpace(ch)) {\n        if (ch === 0x09) {\n          offset += 4 - offset % 4;\n        } else {\n          offset++;\n        }\n      } else {\n        break;\n      }\n\n      pos++;\n    }\n\n    state.tShift[startLine] = pos - posAfterColon;\n    state.sCount[startLine] = offset - initial;\n\n    state.bMarks[startLine] = posAfterColon;\n    state.blkIndent += 4;\n    state.parentType = 'footnote';\n\n    if (state.sCount[startLine] < state.blkIndent) {\n      state.sCount[startLine] += state.blkIndent;\n    }\n\n    state.md.block.tokenize(state, startLine, endLine, true);\n\n    state.parentType = oldParentType;\n    state.blkIndent -= 4;\n    state.tShift[startLine] = oldTShift;\n    state.sCount[startLine] = oldSCount;\n    state.bMarks[startLine] = oldBMark;\n\n    token       = new state.Token('footnote_reference_close', '', -1);\n    token.level = --state.level;\n    state.tokens.push(token);\n\n    return true;\n  }\n\n  // Process inline footnotes (^[...])\n  function footnote_inline(state, silent) {\n    var labelStart,\n        labelEnd,\n        footnoteId,\n        token,\n        tokens,\n        max = state.posMax,\n        start = state.pos;\n\n    if (start + 2 >= max) { return false; }\n    if (state.src.charCodeAt(start) !== 0x5E/* ^ */) { return false; }\n    if (state.src.charCodeAt(start + 1) !== 0x5B/* [ */) { return false; }\n\n    labelStart = start + 2;\n    labelEnd = parseLinkLabel(state, start + 1);\n\n    // parser failed to find ']', so it's not a valid note\n    if (labelEnd < 0) { return false; }\n\n    // We found the end of the link, and know for a fact it's a valid link;\n    // so all that's left to do is to call tokenizer.\n    //\n    if (!silent) {\n      if (!state.env.footnotes) { state.env.footnotes = {}; }\n      if (!state.env.footnotes.list) { state.env.footnotes.list = []; }\n      footnoteId = state.env.footnotes.list.length;\n\n      state.md.inline.parse(\n        state.src.slice(labelStart, labelEnd),\n        state.md,\n        state.env,\n        tokens = []\n      );\n\n      token      = state.push('footnote_ref', '', 0);\n      token.meta = { id: footnoteId };\n\n      state.env.footnotes.list[footnoteId] = { tokens: tokens };\n    }\n\n    state.pos = labelEnd + 1;\n    state.posMax = max;\n    return true;\n  }\n\n  // Process footnote references ([^...])\n  function footnote_ref(state, silent) {\n    var label,\n        pos,\n        footnoteId,\n        footnoteSubId,\n        token,\n        max = state.posMax,\n        start = state.pos;\n\n    // should be at least 4 chars - \"[^x]\"\n    if (start + 3 > max) { return false; }\n\n    if (!state.env.footnotes || !state.env.footnotes.refs) { return false; }\n    if (state.src.charCodeAt(start) !== 0x5B/* [ */) { return false; }\n    if (state.src.charCodeAt(start + 1) !== 0x5E/* ^ */) { return false; }\n\n    for (pos = start + 2; pos < max; pos++) {\n      if (state.src.charCodeAt(pos) === 0x20) { return false; }\n      if (state.src.charCodeAt(pos) === 0x0A) { return false; }\n      if (state.src.charCodeAt(pos) === 0x5D /* ] */) {\n        break;\n      }\n    }\n\n    if (pos === start + 2) { return false; } // no empty footnote labels\n    if (pos >= max) { return false; }\n    pos++;\n\n    label = state.src.slice(start + 2, pos - 1);\n    if (typeof state.env.footnotes.refs[':' + label] === 'undefined') { return false; }\n\n    if (!silent) {\n      if (!state.env.footnotes.list) { state.env.footnotes.list = []; }\n\n      if (state.env.footnotes.refs[':' + label] < 0) {\n        footnoteId = state.env.footnotes.list.length;\n        state.env.footnotes.list[footnoteId] = { label: label, count: 0 };\n        state.env.footnotes.refs[':' + label] = footnoteId;\n      } else {\n        footnoteId = state.env.footnotes.refs[':' + label];\n      }\n\n      footnoteSubId = state.env.footnotes.list[footnoteId].count;\n      state.env.footnotes.list[footnoteId].count++;\n\n      token      = state.push('footnote_ref', '', 0);\n      token.meta = { id: footnoteId, subId: footnoteSubId };\n    }\n\n    state.pos = pos;\n    state.posMax = max;\n    return true;\n  }\n\n  // Glue footnote tokens to end of token stream\n  function footnote_tail(state) {\n    var i, l, j, t, lastParagraph, list, token, tokens, current, currentLabel,\n        insideRef = false,\n        refTokens = {};\n\n    if (!state.env.footnotes) { return; }\n\n    state.tokens = state.tokens.filter(function(tok) {\n      if (tok.type === 'footnote_reference_open') {\n        insideRef = true;\n        current = [];\n        currentLabel = tok.meta.label;\n        return false;\n      }\n      if (tok.type === 'footnote_reference_close') {\n        insideRef = false;\n        // prepend ':' to avoid conflict with Object.prototype members\n        refTokens[':' + currentLabel] = current;\n        return false;\n      }\n      if (insideRef) { current.push(tok); }\n      return !insideRef;\n    });\n\n    if (!state.env.footnotes.list) { return; }\n    list = state.env.footnotes.list;\n\n    token = new state.Token('footnote_block_open', '', 1);\n    state.tokens.push(token);\n\n    for (i = 0, l = list.length; i < l; i++) {\n      token      = new state.Token('footnote_open', '', 1);\n      token.meta = { id: i };\n      state.tokens.push(token);\n\n      if (list[i].tokens) {\n        tokens = [];\n\n        token          = new state.Token('paragraph_open', 'p', 1);\n        token.block    = true;\n        tokens.push(token);\n\n        token          = new state.Token('inline', '', 0);\n        token.children = list[i].tokens;\n        token.content  = '';\n        tokens.push(token);\n\n        token          = new state.Token('paragraph_close', 'p', -1);\n        token.block    = true;\n        tokens.push(token);\n\n      } else if (list[i].label) {\n        tokens = refTokens[':' + list[i].label];\n      }\n\n      state.tokens = state.tokens.concat(tokens);\n      if (state.tokens[state.tokens.length - 1].type === 'paragraph_close') {\n        lastParagraph = state.tokens.pop();\n      } else {\n        lastParagraph = null;\n      }\n\n      t = list[i].count > 0 ? list[i].count : 1;\n      for (j = 0; j < t; j++) {\n        token      = new state.Token('footnote_anchor', '', 0);\n        token.meta = { id: i, subId: j };\n        state.tokens.push(token);\n      }\n\n      if (lastParagraph) {\n        state.tokens.push(lastParagraph);\n      }\n\n      token = new state.Token('footnote_close', '', -1);\n      state.tokens.push(token);\n    }\n\n    token = new state.Token('footnote_block_close', '', -1);\n    state.tokens.push(token);\n  }\n\n  md.block.ruler.before('reference', 'footnote_def', footnote_def, { alt: [ 'paragraph', 'reference' ] });\n  md.inline.ruler.after('image', 'footnote_inline', footnote_inline);\n  md.inline.ruler.after('footnote_inline', 'footnote_ref', footnote_ref);\n  md.core.ruler.after('inline', 'footnote_tail', footnote_tail);\n};\n","// Process definition lists\n//\n'use strict';\n\n\nmodule.exports = function deflist_plugin(md) {\n  var isSpace = md.utils.isSpace;\n\n  // Search `[:~][\\n ]`, returns next pos after marker on success\n  // or -1 on fail.\n  function skipMarker(state, line) {\n    var pos, marker,\n        start = state.bMarks[line] + state.tShift[line],\n        max = state.eMarks[line];\n\n    if (start >= max) { return -1; }\n\n    // Check bullet\n    marker = state.src.charCodeAt(start++);\n    if (marker !== 0x7E/* ~ */ && marker !== 0x3A/* : */) { return -1; }\n\n    pos = state.skipSpaces(start);\n\n    // require space after \":\"\n    if (start === pos) { return -1; }\n\n    // no empty definitions, e.g. \"  : \"\n    if (pos >= max) { return -1; }\n\n    return start;\n  }\n\n  function markTightParagraphs(state, idx) {\n    var i, l,\n        level = state.level + 2;\n\n    for (i = idx + 2, l = state.tokens.length - 2; i < l; i++) {\n      if (state.tokens[i].level === level && state.tokens[i].type === 'paragraph_open') {\n        state.tokens[i + 2].hidden = true;\n        state.tokens[i].hidden = true;\n        i += 2;\n      }\n    }\n  }\n\n  function deflist(state, startLine, endLine, silent) {\n    var ch,\n        contentStart,\n        ddLine,\n        dtLine,\n        itemLines,\n        listLines,\n        listTokIdx,\n        max,\n        nextLine,\n        offset,\n        oldDDIndent,\n        oldIndent,\n        oldParentType,\n        oldSCount,\n        oldTShift,\n        oldTight,\n        pos,\n        prevEmptyEnd,\n        tight,\n        token;\n\n    if (silent) {\n      // quirk: validation mode validates a dd block only, not a whole deflist\n      if (state.ddIndent < 0) { return false; }\n      return skipMarker(state, startLine) >= 0;\n    }\n\n    nextLine = startLine + 1;\n    if (nextLine >= endLine) { return false; }\n\n    if (state.isEmpty(nextLine)) {\n      nextLine++;\n      if (nextLine >= endLine) { return false; }\n    }\n\n    if (state.sCount[nextLine] < state.blkIndent) { return false; }\n    contentStart = skipMarker(state, nextLine);\n    if (contentStart < 0) { return false; }\n\n    // Start list\n    listTokIdx = state.tokens.length;\n    tight = true;\n\n    token     = state.push('dl_open', 'dl', 1);\n    token.map = listLines = [ startLine, 0 ];\n\n    //\n    // Iterate list items\n    //\n\n    dtLine = startLine;\n    ddLine = nextLine;\n\n    // One definition list can contain multiple DTs,\n    // and one DT can be followed by multiple DDs.\n    //\n    // Thus, there is two loops here, and label is\n    // needed to break out of the second one\n    //\n    /*eslint no-labels:0,block-scoped-var:0*/\n    OUTER:\n    for (;;) {\n      prevEmptyEnd = false;\n\n      token          = state.push('dt_open', 'dt', 1);\n      token.map      = [ dtLine, dtLine ];\n\n      token          = state.push('inline', '', 0);\n      token.map      = [ dtLine, dtLine ];\n      token.content  = state.getLines(dtLine, dtLine + 1, state.blkIndent, false).trim();\n      token.children = [];\n\n      token          = state.push('dt_close', 'dt', -1);\n\n      for (;;) {\n        token     = state.push('dd_open', 'dd', 1);\n        token.map = itemLines = [ nextLine, 0 ];\n\n        pos = contentStart;\n        max = state.eMarks[ddLine];\n        offset = state.sCount[ddLine] + contentStart - (state.bMarks[ddLine] + state.tShift[ddLine]);\n\n        while (pos < max) {\n          ch = state.src.charCodeAt(pos);\n\n          if (isSpace(ch)) {\n            if (ch === 0x09) {\n              offset += 4 - offset % 4;\n            } else {\n              offset++;\n            }\n          } else {\n            break;\n          }\n\n          pos++;\n        }\n\n        contentStart = pos;\n\n        oldTight = state.tight;\n        oldDDIndent = state.ddIndent;\n        oldIndent = state.blkIndent;\n        oldTShift = state.tShift[ddLine];\n        oldSCount = state.sCount[ddLine];\n        oldParentType = state.parentType;\n        state.blkIndent = state.ddIndent = state.sCount[ddLine] + 2;\n        state.tShift[ddLine] = contentStart - state.bMarks[ddLine];\n        state.sCount[ddLine] = offset;\n        state.tight = true;\n        state.parentType = 'deflist';\n\n        state.md.block.tokenize(state, ddLine, endLine, true);\n\n        // If any of list item is tight, mark list as tight\n        if (!state.tight || prevEmptyEnd) {\n          tight = false;\n        }\n        // Item become loose if finish with empty line,\n        // but we should filter last element, because it means list finish\n        prevEmptyEnd = (state.line - ddLine) > 1 && state.isEmpty(state.line - 1);\n\n        state.tShift[ddLine] = oldTShift;\n        state.sCount[ddLine] = oldSCount;\n        state.tight = oldTight;\n        state.parentType = oldParentType;\n        state.blkIndent = oldIndent;\n        state.ddIndent = oldDDIndent;\n\n        token = state.push('dd_close', 'dd', -1);\n\n        itemLines[1] = nextLine = state.line;\n\n        if (nextLine >= endLine) { break OUTER; }\n\n        if (state.sCount[nextLine] < state.blkIndent) { break OUTER; }\n        contentStart = skipMarker(state, nextLine);\n        if (contentStart < 0) { break; }\n\n        ddLine = nextLine;\n\n        // go to the next loop iteration:\n        // insert DD tag and repeat checking\n      }\n\n      if (nextLine >= endLine) { break; }\n      dtLine = nextLine;\n\n      if (state.isEmpty(dtLine)) { break; }\n      if (state.sCount[dtLine] < state.blkIndent) { break; }\n\n      ddLine = dtLine + 1;\n      if (ddLine >= endLine) { break; }\n      if (state.isEmpty(ddLine)) { ddLine++; }\n      if (ddLine >= endLine) { break; }\n\n      if (state.sCount[ddLine] < state.blkIndent) { break; }\n      contentStart = skipMarker(state, ddLine);\n      if (contentStart < 0) { break; }\n\n      // go to the next loop iteration:\n      // insert DT and DD tags and repeat checking\n    }\n\n    // Finilize list\n    token = state.push('dl_close', 'dl', -1);\n\n    listLines[1] = nextLine;\n\n    state.line = nextLine;\n\n    // mark paragraphs tight if needed\n    if (tight) {\n      markTightParagraphs(state, listTokIdx);\n    }\n\n    return true;\n  }\n\n\n  md.block.ruler.before('paragraph', 'deflist', deflist, { alt: [ 'paragraph', 'reference' ] });\n};\n"],"sourceRoot":""}